{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a8f0d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import requests as r\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f69f6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randint(0, 100, size=(200000, 200))\n",
    "y = np.random.randint(0, 100, size=(200000, 1))\n",
    "\n",
    "X = list(map(lambda i:  str(i), X.tolist()))\n",
    "y = list(map(lambda i: str(i), y.ravel().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7044edbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'http://0.0.0.0:8000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca1b925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "body1 = {\n",
    "    \"x\": {\"texts\":X},\n",
    "    \"y\": {\"labels\":y},\n",
    "    \"config\":{\n",
    "        \"model_path\": \"lr_test1\",\n",
    "        \"model_type\": \"lr\",\n",
    "        \"feature_type\": \"cnt\",\n",
    "        'params': {'max_iter': 1000}\n",
    "    }\n",
    "}\n",
    "\n",
    "body2 = {\n",
    "    \"x\": {\"texts\":X},\n",
    "    \"y\": {\"labels\":y},\n",
    "    \"config\":{\n",
    "        \"model_path\": \"lr_test2\",\n",
    "        \"model_type\": \"lr\",\n",
    "        \"feature_type\": \"cnt\",\n",
    "        'params': {'max_iter': 1000}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be13a2bf",
   "metadata": {},
   "source": [
    "# Синхронное выполнение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa7c3198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время выполнения в синхронном режиме - 97.74227666854858\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model1 = LogisticRegression(max_iter=1000)\n",
    "data = CountVectorizer().fit_transform(X)\n",
    "model1.fit(data, y)\n",
    "\n",
    "model2 = LogisticRegression(max_iter=1000)\n",
    "data = CountVectorizer().fit_transform(X)\n",
    "model2.fit(data, y)\n",
    "\n",
    "print(f\"Время выполнения в синхронном режиме - {time.time() - start_time}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9bda2a9a",
   "metadata": {},
   "source": [
    "## Асинхронное выполнение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61d47230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время выполнения в асинхронном режиме  - 68.30413961410522\n"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "start_time = 0\n",
    "async def async_requests():\n",
    "    global start_time\n",
    "    start_time = time.time()\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        await session.post(url=f\"{URL}/remove\", json={'model_path': 'lr_test1'})\n",
    "        await session.post(url=f\"{URL}/remove\", json={'model_path': 'lr_test2'})\n",
    "\n",
    "        req_1 = await session.post(url=f\"{URL}/fit\", json=body1, chunked=True)\n",
    "        req_2 = await session.post(url=f\"{URL}/fit\", json=body2, chunked=True)\n",
    "        assert req_1.ok and req_2.ok\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "task = loop.create_task(async_requests())\n",
    "loop.run_until_complete(task)\n",
    "\n",
    "while True:\n",
    "    time.sleep(1)\n",
    "    res1 = r.get(url=f\"{URL}/status/lr_test1\").json()\n",
    "    res2 = r.get(url=f\"{URL}/status/lr_test2\").json()\n",
    "    if res1['saved'] and res2['saved']:\n",
    "        break\n",
    "\n",
    "print(f\"Время выполнения в асинхронном режиме  - {time.time() - start_time}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a682f0dd",
   "metadata": {},
   "source": [
    "### Предельное количество процессов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a26731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = {\n",
    "    \"x\": {\"texts\":X},\n",
    "    \"y\": {\"labels\":y},\n",
    "    \"config\":{\n",
    "        \"model_path\": \"test\",\n",
    "        \"model_type\": \"lr\",\n",
    "        \"feature_type\": \"cnt\",\n",
    "        'params': {'max_iter': 1000}\n",
    "    }\n",
    "}\n",
    "\n",
    "body1 = {\n",
    "    \"x\": {\"texts\":X},\n",
    "    \"y\": {\"labels\":y},\n",
    "    \"config\":{\n",
    "        \"model_path\": \"test1\",\n",
    "        \"model_type\": \"lr\",\n",
    "        \"feature_type\": \"cnt\",\n",
    "        'params': {'max_iter': 1000}\n",
    "    }\n",
    "}\n",
    "\n",
    "body2 = {\n",
    "    \"x\": {\"texts\":X},\n",
    "    \"y\": {\"labels\":y},\n",
    "    \"config\":{\n",
    "        \"model_path\": \"test2\",\n",
    "        \"model_type\": \"lr\",\n",
    "        \"feature_type\": \"cnt\",\n",
    "        'params': {'max_iter': 1000}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32a6d458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': False, 'message': 'No free process', 'traceback': None}\n"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "start_time = 0\n",
    "async def async_requests():\n",
    "    global start_time\n",
    "    start_time = time.time()\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        await session.post(url=f\"{URL}/fit\", json=body, chunked=True)\n",
    "        await session.post(url=f\"{URL}/fit\", json=body1, chunked=True)\n",
    "        await session.post(url=f\"{URL}/fit\", json=body2, chunked=True)\n",
    "        await session.post(url=f\"{URL}/fit\", json=body2, chunked=True)\n",
    "        res = await session.post(url=f\"{URL}/fit\", json=body2, chunked=True)\n",
    "        print(await res.json())\n",
    "\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "task = loop.create_task(async_requests())\n",
    "loop.run_until_complete(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0d34b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_body1 = {\n",
    "    \"x\": {\"texts\":X},\n",
    "    \"config\":{\n",
    "        \"model_path\": \"lr_test1\",\n",
    "    }\n",
    "}\n",
    "\n",
    "pr_body2 = {\n",
    "    \"x\": {\"texts\":X},\n",
    "    \"config\":{\n",
    "        \"model_path\": \"lr_test2\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "762b1e7d",
   "metadata": {},
   "source": [
    "### Загрузим модели в режим инференса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e712e470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'saved': True, 'inference': True}\n",
      "{'saved': True, 'inference': True}\n"
     ]
    }
   ],
   "source": [
    "r.post(url=f\"{URL}/load\", json={'model_path': 'lr_test1'})\n",
    "r.post(url=f\"{URL}/load\", json={'model_path': 'lr_test2'})\n",
    "\n",
    "status1 = r.get(url=f\"{URL}/status/lr_test1\").json()\n",
    "print(status1)\n",
    "status2 = r.get(url=f\"{URL}/status/lr_test2\").json()\n",
    "print(status2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbe639ad",
   "metadata": {},
   "source": [
    "### Предельный случай загрузки в инференс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "091397fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': True, 'message': 'Max amount of loaded models', 'traceback': None}\n"
     ]
    }
   ],
   "source": [
    "r.post(url=f\"{URL}/load\", json={'model_path': 'test'})\n",
    "r.post(url=f\"{URL}/load\", json={'model_path': 'test1'})\n",
    "res = r.post(url=f\"{URL}/load\", json={'model_path': 'test2'})\n",
    "print(res.json())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2f680e4",
   "metadata": {},
   "source": [
    "## Запустим предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05e23d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def async_predict():\n",
    "    async with aiohttp.ClientSession() as session1:\n",
    "        await session1.post(url=f\"{URL}/predict\", json=pr_body1, chunked=True)\n",
    "        await session1.post(url=f\"{URL}/predict\", json=pr_body2, chunked=True)    \n",
    "        \n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "task = loop.create_task(async_predict())\n",
    "loop.run_until_complete(task)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7bb9a461",
   "metadata": {},
   "source": [
    "### Пример выгрузки модели из режима инференса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0af17964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'saved': True, 'inference': False}\n",
      "{'saved': True, 'inference': False}\n"
     ]
    }
   ],
   "source": [
    "r.post(url=f\"{URL}/unload\", json={'model_path': 'lr_test1'})\n",
    "r.post(url=f\"{URL}/unload\", json={'model_path': 'lr_test2'})\n",
    "status1 = r.get(url=f\"{URL}/status/lr_test1\").json()\n",
    "print(status1)\n",
    "status2 = r.get(url=f\"{URL}/status/lr_test2\").json()\n",
    "print(status2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f02387d",
   "metadata": {},
   "source": [
    "### Пример удаления модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7ac80d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'saved': False, 'inference': False}\n"
     ]
    }
   ],
   "source": [
    "r.post(url=f\"{URL}/remove\", json={'model_path': 'lr_test1'})\n",
    "status1 = r.get(url=f\"{URL}/status/lr_test1\").json()\n",
    "print(status1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c1f2c96",
   "metadata": {},
   "source": [
    "### Пример удаления всех моделей\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "526ee66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'saved': False, 'inference': False}\n"
     ]
    }
   ],
   "source": [
    "r.post(url=f\"{URL}/remove_all\")\n",
    "status1 = r.get(url=f\"{URL}/status/lr_test2\").json()\n",
    "print(status1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
